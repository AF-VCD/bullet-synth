{"cells":[{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","\n","# stuff for this notebook to work in kaggle\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","\n","import time"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","tf.debugging.set_log_device_placement(True)\n","assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n","for gpu in physical_devices:\n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"code","execution_count":26,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Length of text: 4461059 characters\n112 unique characters\n- Pivotal player in 2009 Pumpkin Patrol; ensured safety of kids in base housing while trick-or-treating--promote!\n- CAT exec for Air show; enabled coord btwn Wg and civ agencies--104K attendees awed by air power display\n- Coordinated six sports activ\n{\n  &#39;\\t&#39;:   0,\n  &#39;\\n&#39;:   1,\n  &#39; &#39; :   2,\n  &#39;!&#39; :   3,\n  &#39;&quot;&#39; :   4,\n  &#39;#&#39; :   5,\n  &#39;$&#39; :   6,\n  &#39;%&#39; :   7,\n  &#39;&amp;&#39; :   8,\n  &quot;&#39;&quot; :   9,\n  &#39;(&#39; :  10,\n  &#39;)&#39; :  11,\n  &#39;*&#39; :  12,\n  &#39;+&#39; :  13,\n  &#39;,&#39; :  14,\n  &#39;-&#39; :  15,\n  &#39;.&#39; :  16,\n  &#39;/&#39; :  17,\n  &#39;0&#39; :  18,\n  &#39;1&#39; :  19,\n  ...\n}\n&#39;- Pivotal pla&#39; ---- MAPS TO ---- &gt; [15  2 50 75 88 81 86 67 78  2 82 78 67]\n"}],"source":["path_to_file = './bullets.txt'\n","# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print ('Length of text: {} characters'.format(len(text)))\n","\n","# The unique characters in the file\n","vocab = sorted(set(text))\n","print ('{} unique characters'.format(len(vocab)))\n","\n","# Take a look at the first 250 characters in text\n","print(text[:250])\n","\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","text_as_int = np.array([char2idx[c] for c in text])\n","\n","print('{')\n","for char,_ in zip(char2idx, range(20)):\n","    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n","print('  ...\\n}')\n","\n","# Show how the first 13 characters from the text are mapped to integers\n","print ('{} ---- MAPS TO ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"]},{"cell_type":"code","execution_count":27,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"-\n \nP\ni\nv\no\nt\na\nl\n \n"}],"source":["# The maximum length sentence we want for a single input in characters\n","seq_length = 250\n","\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","# Create training examples / targets. \n","# char_dataset is one basically one long 1d array with every element in there.\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","\n","for i in char_dataset.take(10):\n","  print(idx2char[i.numpy()])"]},{"cell_type":"code","execution_count":28,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"&#39;- Pivotal player in 2009 Pumpkin Patrol; ensured safety of kids in base housing while trick-or-treating--promote!\\n- CAT exec for Air show; enabled coord btwn Wg and civ agencies--104K attendees awed by air power display\\n- Coordinated six sports activi&#39;\n&#39;ties at Gp picnic; boosted morale/fostered camaraderie of 500--promote soonest!\\n- Maintained 43 servers; applied 75 vital patches; protected $322K hardware/$97K in software--99% up-time\\n- Coordinated migration of C2 Remedy development enclave; facilit&#39;\n&#39;ated development on C2 ticket tracking sys\\n- Installed 33 applications on testing servers; identified 4 errors--integral to Sq software engineering life cycle\\n- Enthusiastic Flt CFC representative; achieved 100% personnel contact--ensured squadron met&#39;\n&#39; campaign goals\\n- Augmented Security Forces at Scott AFB 2009 airshow--ensured security of 150K spectators &amp; 76 performers\\n- Earned 12 credits for Computer Science degree at Southwestern Illinois College; maintained excellent 3.8 GPA\\n- Self-taught Win&#39;\n&#39;dows Server 2008 concepts; anticipated future AF migration--evaluated impact on 35 projects\\n- Trained, evaluated &amp; tracked readiness for 44 flight prsnl--administered 11 PT tests/led 38 Sq/Flt PT sessions\\n- Updated certificates on testing domain contr&#39;\n"}],"source":["sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for item in sequences.take(5):\n","  print(repr(''.join(idx2char[item.numpy()])))"]},{"cell_type":"code","execution_count":29,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"}],"source":["def split_input_target(chunk):\n","    input_text = chunk[:-1]\n","    target_text = chunk[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)"]},{"cell_type":"code","execution_count":30,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Input data:  &#39;- Pivotal player in 2009 Pumpkin Patrol; ensured safety of kids in base housing while trick-or-treating--promote!\\n- CAT exec for Air show; enabled coord btwn Wg and civ agencies--104K attendees awed by air power display\\n- Coordinated six sports activ&#39;\nTarget data: &#39; Pivotal player in 2009 Pumpkin Patrol; ensured safety of kids in base housing while trick-or-treating--promote!\\n- CAT exec for Air show; enabled coord btwn Wg and civ agencies--104K attendees awed by air power display\\n- Coordinated six sports activi&#39;\n"}],"source":["for input_example, target_example in  dataset.take(1):\n","  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"]},{"cell_type":"code","execution_count":31,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Step    0\n  input: 15 (&#39;-&#39;)\n  expected output: 2 (&#39; &#39;)\nStep    1\n  input: 2 (&#39; &#39;)\n  expected output: 50 (&#39;P&#39;)\nStep    2\n  input: 50 (&#39;P&#39;)\n  expected output: 75 (&#39;i&#39;)\nStep    3\n  input: 75 (&#39;i&#39;)\n  expected output: 88 (&#39;v&#39;)\nStep    4\n  input: 88 (&#39;v&#39;)\n  expected output: 81 (&#39;o&#39;)\n"}],"source":["for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n","    print(\"Step {:4d}\".format(i))\n","    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n","    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"]},{"cell_type":"code","execution_count":32,"metadata":{"tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":"&lt;BatchDataset shapes: ((128, 250), (128, 250)), types: (tf.int32, tf.int32)&gt;"},"metadata":{},"execution_count":32}],"source":["# Batch size - the number of simultaneous samples to evaluate on each training step. \n","#  So for a given model step, BATCH_SIZE number examples are run through the model at that step, and the results for those \n","#  BATCH_SIZE examples are compared to their respective \"correct answers,\" and the resulting averaged or weighted averaged delta\n","#  is used to adjust the model for the next training set. \n","BATCH_SIZE = 128\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","dataset"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 512\n","\n","# Number of RNN units\n","rnn_units = 1024"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                              return_sequences=True,\n","                              stateful=True,\n","                              recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.LSTM(rnn_units,\n","                              return_sequences=True,\n","                              stateful=True,\n","                              recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model"]},{"cell_type":"code","execution_count":35,"metadata":{"tags":[]},"outputs":[],"source":["model = build_model(\n","  vocab_size = len(vocab),\n","  embedding_dim=embedding_dim,\n","  rnn_units=rnn_units,\n","  batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":36,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"(128, 250, 112) # (batch_size, sequence_length, vocab_size)\n"}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","  example_batch_predictions = model(input_example_batch)\n","  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"code","execution_count":37,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: &quot;sequential_1&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (128, None, 512)          57344     \n_________________________________________________________________\nlstm_2 (LSTM)                (128, None, 1024)         6295552   \n_________________________________________________________________\nlstm_3 (LSTM)                (128, None, 1024)         8392704   \n_________________________________________________________________\ndense_1 (Dense)              (128, None, 112)          114800    \n=================================================================\nTotal params: 14,860,400\nTrainable params: 14,860,400\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["model.summary()"]},{"cell_type":"code","execution_count":38,"metadata":{"tags":[]},"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([ 45,  49,  58,  97,  75,  63,  92,  14,  43,   9,  19,   5, 102,\n        89,  30,  29,  12,  79,  17,  91,   7,  71,  30,  34,  12,  97,\n        29,  19,  96,  40, 101,  31,   1,  81,  56,  29,  12,  25,  20,\n        46,  56,  21,  98,  37,  33,  72,  29, 101,  28,  67,  81,  96,\n        38,  58, 105,  25,   5,  87,   5,  80,  29,  17,  85,  37,  56,\n        29,  29,  18,  77,  75,  90,  31,  88,  86,  36,  79, 109,   0,\n         9,  61,   1,  20,  22,  44,  12,  57,  53,  25,  62,  73,  55,\n        73,  48,  21, 104,  63,  12,  26,  67,  51,  62,  87,   1,  51,\n       109, 101,  14,  77,  91,  81,  18,  64,  62,  80,  84,  16,  73,\n        50,  27,  87,  11,  74,  71, 106,  87,  40,  54,  95,   3,  19,\n        46,  67,  71,  65,  10,  75,  40,  80, 101,  40,  92,  66,  22,\n        72,  38,  66,  11,  41,  16,  11,   0,   7,  48,  37,  12,   0,\n        19,  28,  99,  74, 110,  38,  17,   2,  13, 108,  45,  64,  34,\n        66,   0,  90,  76,  10, 111,  87,  66,   0,  76,  90,  97,  67,\n        44, 107,  36,  94,  22,   4,   8,   6,  56,  19, 101,  73,  77,\n        68, 110, 109,  45,  77,  65,   0, 102,   5,  49,  17,  50,  14,\n        66,  76,  38,  58,  86,  11, 104,  73,   8,  41,  17,  36,  77,\n        86,  14, 108,   5,  27,  41,   0,  54,  36,  70,  93, 105,  32,\n        73,  62,  87,  57,  80,  43,  72,  40,  69,  35,  52,  71,  39,\n        52,  50,   5], dtype=int64)"},"metadata":{},"execution_count":38}],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n","sampled_indices"]},{"cell_type":"code","execution_count":39,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Input: \n &#39;ht line use\\n- Installed new engine with minimal descrepencies after 7-level inspection--received excellent rating from QA\\n- Skillful mechanic; repaired hydraulic test stand pressure compensator--saved over $2,300 in replacement costs\\n- 56 Ways/Means &#39;\n\nNext Char Predictions: \n &#39;KOX²i]z,I\\&#39;1#\\u2009w&lt;;*m/y%e&lt;@*²;1°F\\u2006=\\noV;*72LV3³C?f;\\u2006:ao°DX‘7#u#n;/sCV;;0kix=vtBm•\\t\\&#39;[\\n24J*WS7\\\\gUgN3—]*8aQ\\\\u\\nQ•\\u2006,kyo0^\\\\nr.gP9u)he’uFT~!1Lae_(iFn\\u2006Fz`4fD`)G.)\\t%NC*\\t1:éh…D/ +”K^@`\\txj(\\U00100bd7u`\\tjx²aJ“B}4&quot;&amp;$V1\\u2006gkb…•Kk_\\t\\u2009#O/P,`jDXt)—g&amp;G/Bkt,”#9G\\tTBd{‘&gt;g\\\\uWnIfFcAReERP#&#39;\n"}],"source":["print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n","print()\n","print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"]},{"cell_type":"code","execution_count":40,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Prediction shape:  (128, 250, 112)  # (batch_size, sequence_length, vocab_size)\nscalar_loss:       4.7187686\n"}],"source":["def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["EPOCHS=30"]},{"cell_type":"code","execution_count":44,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Executing op DatasetCardinality in device /job:localhost/replica:0/task:0/device:CPU:0\nEpoch 1/30\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op __inference_initialize_variables_10054 in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op __inference_distributed_function_12246 in device /job:localhost/replica:0/task:0/device:GPU:0\n    138/Unknown - 73s 525ms/step - loss: 2.9579Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op SaveV2 in device /job:localhost/replica:0/task:0/device:CPU:0\nExecuting op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\nExecuting op MergeV2Checkpoints in device /job:localhost/replica:0/task:0/device:CPU:0\n138/138 [==============================] - 78s 562ms/step - loss: 2.9579\nEpoch 2/30\n138/138 [==============================] - 75s 540ms/step - loss: 1.9497\nEpoch 3/30\n138/138 [==============================] - 75s 541ms/step - loss: 1.4991\nEpoch 4/30\n138/138 [==============================] - 75s 544ms/step - loss: 1.3497\nEpoch 5/30\n138/138 [==============================] - 76s 548ms/step - loss: 1.2697\nEpoch 6/30\n138/138 [==============================] - 75s 543ms/step - loss: 1.2149\nEpoch 7/30\n138/138 [==============================] - 75s 541ms/step - loss: 1.1704\nEpoch 8/30\n138/138 [==============================] - 75s 543ms/step - loss: 1.1315\nEpoch 9/30\n138/138 [==============================] - 75s 547ms/step - loss: 1.0966\nEpoch 10/30\n138/138 [==============================] - 75s 546ms/step - loss: 1.0636\nEpoch 11/30\n138/138 [==============================] - 75s 543ms/step - loss: 1.0307\nEpoch 12/30\n138/138 [==============================] - 74s 538ms/step - loss: 0.9996\nEpoch 13/30\n138/138 [==============================] - 75s 544ms/step - loss: 0.9678\nEpoch 14/30\n138/138 [==============================] - 75s 540ms/step - loss: 0.9363\nEpoch 15/30\n138/138 [==============================] - 75s 541ms/step - loss: 0.9037\nEpoch 16/30\n138/138 [==============================] - 75s 542ms/step - loss: 0.8723\nEpoch 17/30\n138/138 [==============================] - 75s 546ms/step - loss: 0.8405\nEpoch 18/30\n138/138 [==============================] - 75s 543ms/step - loss: 0.8077\nEpoch 19/30\n138/138 [==============================] - 75s 545ms/step - loss: 0.7758\nEpoch 20/30\n138/138 [==============================] - 74s 539ms/step - loss: 0.7456\nEpoch 21/30\n138/138 [==============================] - 76s 548ms/step - loss: 0.7149\nEpoch 22/30\n138/138 [==============================] - 75s 544ms/step - loss: 0.6849\nEpoch 23/30\n138/138 [==============================] - 74s 539ms/step - loss: 0.6550\nEpoch 24/30\n138/138 [==============================] - 74s 540ms/step - loss: 0.6269\nEpoch 25/30\n138/138 [==============================] - 75s 545ms/step - loss: 0.5999\nEpoch 26/30\n138/138 [==============================] - 74s 538ms/step - loss: 0.5744\nEpoch 27/30\n138/138 [==============================] - 75s 542ms/step - loss: 0.5497\nEpoch 28/30\n138/138 [==============================] - 75s 546ms/step - loss: 0.5256\nEpoch 29/30\n138/138 [==============================] - 76s 552ms/step - loss: 0.5032\nEpoch 30/30\n138/138 [==============================] - 76s 547ms/step - loss: 0.4828\n"}],"source":["with tf.device('/GPU:0'):   # GPU:/1 uses my GTX 970, it's the opposite of what is listed in task manager. With two LSTM layers, 970 couldn't handle I think.\n","    history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"&#39;./training_checkpoints\\\\ckpt_30&#39;"},"metadata":{},"execution_count":45}],"source":["tf.train.latest_checkpoint(checkpoint_dir)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["model.save('bullets-lstm.h5')"]},{"cell_type":"code","execution_count":47,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\nExecuting op RestoreV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"}],"source":["# For the purposes of evaluating the model, setting the batch size to 1 so you can train one thing at a time.\n","\n","model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"]},{"cell_type":"code","execution_count":48,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: &quot;sequential_2&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (1, None, 512)            57344     \n_________________________________________________________________\nlstm_4 (LSTM)                (1, None, 1024)           6295552   \n_________________________________________________________________\nlstm_5 (LSTM)                (1, None, 1024)           8392704   \n_________________________________________________________________\ndense_2 (Dense)              (1, None, 112)            114800    \n=================================================================\nTotal params: 14,860,400\nTrainable params: 14,860,400\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["model.summary()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["model.save('bullets-lstm_built.h5')"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 1000\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 0.5\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      #print(input_eval)\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the word returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted word as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","      \n","      text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"]},{"cell_type":"code","execution_count":51,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Executing op ExpandDims in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op Squeeze in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op RealDiv in device /job:localhost/replica:0/task:0/device:GPU:0\nExecuting op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n-5kMk&quot;+J4BTVLTTY4B/8BTF/FY07KB/BY0BQBYBUTY&gt;22B7*6********************************XXXXXXXXX=X%VVVV*******************************Tkk&amp;JJVTJVBVBBBOMBUTYVRBBTBYBYBRRYBRRYBRRYBORYBETBYBBYBBYBBYBBBUTYBEBBYBRBYBEBYBYBEEYBLEYEY__BRPQBWYBBUTUBYBUBUBUBUBWLLUABPBUBQUYYBYBPBRVMBPPRBRRVOYROOSYPPRBUTPPRHPR)BTBRNY0MMXBYBUHBBYBUBYBERBYBQBQPLLLYTCBOTVCOPERBYBRYBEREYBYBEYB)B08822k_BB:_888*______96J22H/_99%) FSF&#39;s--sustained digital success\n- Authored 1st DOD monitor trng; integrated 27 prsnl in critical procedures--enabled safe alternative storage/increased security posture\n- Led DV visit; IG lead for AF&#39;s lrgst CGO mod w/$4M; pursued pers expenses--CSAF/CC coined Excellence Awd\n- Taught 120 hrs/guided resiliency--supported new AF resources/all future enlisted\n- Community asset; helped organized children&#39;s park raiser/averted $1.2K in mission critical parts\n- Integrated electronic file plan; tracked documents for secure network library--safeguarded $1B in assets\n- Engineered Wg OPSEC container at Fabrica\n"}],"source":["print(generate_text(model, start_string=u\"-\"))"]},{"cell_type":"code","execution_count":52,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"- Led7$7773%&quot;UTDY&amp;&quot; TG&amp;ERDSS? QVI/ICTK sortie msn ready\n- Developed QA vehicle fleet; designed/insp&#39;d fleet/gen rqmt--enabled 1st ever PACOM B-1/B2/B-52 joint BAAD msns\n- Aced CAF Instructor courses; trained on inspection/user attendees for future success--earned CU w/ 3.8 GPA\n- Pursued CCAF degree in Aviation Maint Program--Fit Foreign Military Combined One vacantais and operations; promote!\n- Deployed to Korean duty status plat; transmitted 29 vital deployed personnel--enabled 300 base populace and 133 sorties\n- Assists w/ managing all aspects of evidence/discipline &amp; unlimited potential--continue to promote!\n- Active member of Airman Against Drunk Driving course; increased unit&#39;s critical capabilities by 25%\n- Led 15 mbr loading of 10K user accts, enabled 1.5K sorties--spt&#39;d 124 sorties/832 hrs, FY09\n- Drove ADPE pgm; analyzed 12K line items/$1.2M directly aided flew 88 AEW mission benefits\n- Directed 6 mbr tm; moved 114 tons of cargo in spt of for OEF--flt airlifted two day event\n- Orch\n"}],"source":["print(generate_text(model, start_string=u\"- Led\"))\n"]},{"cell_type":"code","execution_count":53,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"- Led 6 org test event; 370 parts/$50K--ensured safe transportation for 100 Airmen\n- Team lead for aircraft deployer; reduced response time from 12 months--ensured code 1 ATO sorties\n- Formulated exer setup; organized 2 STs/$9M of materials--cut failures from 78% to 4.0%\n- Restored secure mounts/personnel support daily acft main activation sys; ensured operational readiness--100% accountability\n- Assisted crypto inventory; contributed to OMC&#39;s only finalized ACC 2-yr beddown plan; 320 pallets fired--$6.9M in EW assets secured\n- Coordinated 216 RISA redistributions; validated part/complex sys release--recouped $25K in AF assets\n- Oversaw fund raiser; Guided 10 prsnl thru 4 day council fundraiser--raised $280/118 for American Legion Stores\n- Mentored std mil training sememonizations--committed to improving 4-level communication system integrity\n- Assumed NCOIC role; lead four exercises/two techs to lead tremendous medical docs--ensured safe operation\n- Assists 4 technicians contributed to &quot;Excellent&quot; rating du\n"}],"source":["print(generate_text(model, start_string=u\"- Led 6 org test event;\"))"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"&#39;{&quot;\\\\t&quot;: 0, &quot;\\\\n&quot;: 1, &quot; &quot;: 2, &quot;!&quot;: 3, &quot;\\\\&quot;&quot;: 4, &quot;#&quot;: 5, &quot;$&quot;: 6, &quot;%&quot;: 7, &quot;&amp;&quot;: 8, &quot;\\&#39;&quot;: 9, &quot;(&quot;: 10, &quot;)&quot;: 11, &quot;*&quot;: 12, &quot;+&quot;: 13, &quot;,&quot;: 14, &quot;-&quot;: 15, &quot;.&quot;: 16, &quot;/&quot;: 17, &quot;0&quot;: 18, &quot;1&quot;: 19, &quot;2&quot;: 20, &quot;3&quot;: 21, &quot;4&quot;: 22, &quot;5&quot;: 23, &quot;6&quot;: 24, &quot;7&quot;: 25, &quot;8&quot;: 26, &quot;9&quot;: 27, &quot;:&quot;: 28, &quot;;&quot;: 29, &quot;&lt;&quot;: 30, &quot;=&quot;: 31, &quot;&gt;&quot;: 32, &quot;?&quot;: 33, &quot;@&quot;: 34, &quot;A&quot;: 35, &quot;B&quot;: 36, &quot;C&quot;: 37, &quot;D&quot;: 38, &quot;E&quot;: 39, &quot;F&quot;: 40, &quot;G&quot;: 41, &quot;H&quot;: 42, &quot;I&quot;: 43, &quot;J&quot;: 44, &quot;K&quot;: 45, &quot;L&quot;: 46, &quot;M&quot;: 47, &quot;N&quot;: 48, &quot;O&quot;: 49, &quot;P&quot;: 50, &quot;Q&quot;: 51, &quot;R&quot;: 52, &quot;S&quot;: 53, &quot;T&quot;: 54, &quot;U&quot;: 55, &quot;V&quot;: 56, &quot;W&quot;: 57, &quot;X&quot;: 58, &quot;Y&quot;: 59, &quot;Z&quot;: 60, &quot;[&quot;: 61, &quot;\\\\\\\\&quot;: 62, &quot;]&quot;: 63, &quot;^&quot;: 64, &quot;_&quot;: 65, &quot;`&quot;: 66, &quot;a&quot;: 67, &quot;b&quot;: 68, &quot;c&quot;: 69, &quot;d&quot;: 70, &quot;e&quot;: 71, &quot;f&quot;: 72, &quot;g&quot;: 73, &quot;h&quot;: 74, &quot;i&quot;: 75, &quot;j&quot;: 76, &quot;k&quot;: 77, &quot;l&quot;: 78, &quot;m&quot;: 79, &quot;n&quot;: 80, &quot;o&quot;: 81, &quot;p&quot;: 82, &quot;q&quot;: 83, &quot;r&quot;: 84, &quot;s&quot;: 85, &quot;t&quot;: 86, &quot;u&quot;: 87, &quot;v&quot;: 88, &quot;w&quot;: 89, &quot;x&quot;: 90, &quot;y&quot;: 91, &quot;z&quot;: 92, &quot;{&quot;: 93, &quot;}&quot;: 94, &quot;~&quot;: 95, &quot;\\\\u00b0&quot;: 96, &quot;\\\\u00b2&quot;: 97, &quot;\\\\u00b3&quot;: 98, &quot;\\\\u00e9&quot;: 99, &quot;\\\\u00f3&quot;: 100, &quot;\\\\u2006&quot;: 101, &quot;\\\\u2009&quot;: 102, &quot;\\\\u2013&quot;: 103, &quot;\\\\u2014&quot;: 104, &quot;\\\\u2018&quot;: 105, &quot;\\\\u2019&quot;: 106, &quot;\\\\u201c&quot;: 107, &quot;\\\\u201d&quot;: 108, &quot;\\\\u2022&quot;: 109, &quot;\\\\u2026&quot;: 110, &quot;\\\\udbc2\\\\udfd7&quot;: 111}&#39;"},"metadata":{},"execution_count":54}],"source":["import 57.dumps(char2idx)\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"&#39;[&quot;\\\\t&quot;, &quot;\\\\n&quot;, &quot; &quot;, &quot;!&quot;, &quot;\\\\&quot;&quot;, &quot;#&quot;, &quot;$&quot;, &quot;%&quot;, &quot;&amp;&quot;, &quot;\\&#39;&quot;, &quot;(&quot;, &quot;)&quot;, &quot;*&quot;, &quot;+&quot;, &quot;,&quot;, &quot;-&quot;, &quot;.&quot;, &quot;/&quot;, &quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;:&quot;, &quot;;&quot;, &quot;&lt;&quot;, &quot;=&quot;, &quot;&gt;&quot;, &quot;?&quot;, &quot;@&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;I&quot;, &quot;J&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;, &quot;N&quot;, &quot;O&quot;, &quot;P&quot;, &quot;Q&quot;, &quot;R&quot;, &quot;S&quot;, &quot;T&quot;, &quot;U&quot;, &quot;V&quot;, &quot;W&quot;, &quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;, &quot;[&quot;, &quot;\\\\\\\\&quot;, &quot;]&quot;, &quot;^&quot;, &quot;_&quot;, &quot;`&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;, &quot;j&quot;, &quot;k&quot;, &quot;l&quot;, &quot;m&quot;, &quot;n&quot;, &quot;o&quot;, &quot;p&quot;, &quot;q&quot;, &quot;r&quot;, &quot;s&quot;, &quot;t&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;, &quot;{&quot;, &quot;}&quot;, &quot;~&quot;, &quot;\\\\u00b0&quot;, &quot;\\\\u00b2&quot;, &quot;\\\\u00b3&quot;, &quot;\\\\u00e9&quot;, &quot;\\\\u00f3&quot;, &quot;\\\\u2006&quot;, &quot;\\\\u2009&quot;, &quot;\\\\u2013&quot;, &quot;\\\\u2014&quot;, &quot;\\\\u2018&quot;, &quot;\\\\u2019&quot;, &quot;\\\\u201c&quot;, &quot;\\\\u201d&quot;, &quot;\\\\u2022&quot;, &quot;\\\\u2026&quot;, &quot;\\\\udbc2\\\\udfd7&quot;]&#39;"},"metadata":{},"execution_count":55}],"source":["json.dumps(vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.5-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}